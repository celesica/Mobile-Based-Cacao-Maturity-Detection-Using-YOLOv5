{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "collapsed_sections": [
        "j2Q0k-azxGe-",
        "7mGmQbAO5pQb",
        "SDIhrBF0sPaM",
        "UwJx-2NHsYxT",
        "kJVs_4zEeVbF",
        "N3qM6T0W53gh",
        "_uPq9mVgiBql"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/celesica/Mobile-Based-Cacao-Maturity-Detection-Using-YOLOv5/blob/main/Google%2520Colab%2520Notebook/Cacao_Maturity_Detection_(YOLOv5)_Custom_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD9gUQpaBxNa"
      },
      "source": [
        "# **Cacao Maturity Detection**\n",
        "## Custom Training with YOLOv5 Model\n",
        "\n",
        "This notebook is based on the [YOLOv5 repository](https://github.com/ultralytics/yolov5) by [Ultralytics](https://www.ultralytics.com/) and [YOLOv5 training blog post](https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/) by [Roboflow](https://roboflow.com).\n",
        "\n",
        "### Steps Covered in this Training:\n",
        "\n",
        "* Install Comet ML for Logging/Visualization\n",
        "* Install YOLOv5 dependencies\n",
        "* Download the UF18 Cacao Maturity dataset from Roboflow\n",
        "* Write the YOLOv5 training configuration\n",
        "* Run YOLOv5 model training\n",
        "* Evaluate the model's performance\n",
        "* Visualize the model's training data\n",
        "* Run the model's inference on test images\n",
        "* Export saved YOLOv5 weights to TensorFlow Lite formats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Install Comet ML for Logging/Visualization\n",
        "\n",
        "Create an account in [Comet ML](https://comet.ml/) if you haven't already, and follow the instructions."
      ],
      "metadata": {
        "id": "j2Q0k-azxGe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install comet_ml --quiet"
      ],
      "metadata": {
        "id": "hQnKYbaCxJv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import comet_ml\n",
        "comet_ml.init(project_name='cacao-maturity-detection')"
      ],
      "metadata": {
        "id": "k9_SptkOxL0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Step 2: Install YOLOv5 Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model & config file exporting folder\n",
        "%mkdir /content/exported_files\n",
        "INFO_FILE = \"/content/exported_files/info.txt\"\n",
        "!touch $INFO_FILE\n",
        "!echo \"Info File:\" $INFO_FILE"
      ],
      "metadata": {
        "id": "q4iG1ALVqijS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clone YOLOv5 repository\n",
        "%cd /content\n",
        "!echo \"git clone https://github.com/ultralytics/yolov5\" # check the cloning script\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd /content/yolov5\n",
        "!git log -n 1 # check the latest commit"
      ],
      "metadata": {
        "id": "wUg6S60p4lNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "%cd /content/yolov5\n",
        "\n",
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "!pip install -q roboflow\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDIhrBF0sPaM"
      },
      "source": [
        "# Step 3: Download the UF18 Cacao Maturity Dataset\n",
        "\n",
        "Download the [UF18 Cacao Maturity Dataset](https://universe.roboflow.com/thesiscacaov1/uf18-cacao-maturity) from Roboflow Universe. It uses the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug_PhK1oqwQA"
      },
      "source": [
        "%cd /content/yolov5\n",
        "#after following the link above, recieve python code with these fields filled in\n",
        "#from roboflow import Roboflow\n",
        "#rf = Roboflow(api_key=\"YOUR API KEY HERE\")\n",
        "#project = rf.workspace().project(\"YOUR PROJECT\")\n",
        "#dataset = project.version(\"YOUR VERSION\").download(\"yolov5\")\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"API-KEY\")\n",
        "project = rf.workspace(\"thesiscacaov1\").project(\"uf18-cacao-v3\")\n",
        "dataset = project.version(3).download(\"yolov5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ3DmmGQztJj"
      },
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat {dataset.location}/data.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the epoch number, image size & prefered model file for training\n",
        "EPOCHS = 1000\n",
        "IMG_SIZE = 640\n",
        "MODEL = \"yolov5s.pt\"\n",
        "MODEL_CONF = \"/content/yolov5/models/yolov5s.yaml\"\n",
        "\n",
        "!echo \"Epoch:\" $EPOCHS >> $INFO_FILE\n",
        "!echo \"Image size:\" $IMG_SIZE >> $INFO_FILE\n",
        "!echo \"Base model:\" $MODEL >> $INFO_FILE\n",
        "!echo \"Base model config file:\" $MODEL_CONF >> $INFO_FILE"
      ],
      "metadata": {
        "id": "sDsVQZ8s_N8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwJx-2NHsYxT"
      },
      "source": [
        "# Step 4: Define Model Configuration and Architecture\n",
        "\n",
        "Write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rvt5wilnDyX"
      },
      "source": [
        "#this is the model configuration\n",
        "%cat $MODEL_CONF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPn9wjOAwwK"
      },
      "source": [
        "# copy the cacao dataset YAML file\n",
        "%cp $MODEL_CONF /content/yolov5/models/cacaov1_model.yaml\n",
        "\n",
        "\n",
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDxebz13RdRA"
      },
      "source": [
        "\n",
        "with open('/content/yolov5/models/cacaov1_model.yaml' , 'r') as f:\n",
        "\n",
        "    #read file\n",
        "    file_source = f.read()\n",
        "\n",
        "    #replace 'nc:' with the num_classes in the file\n",
        "    new_string = 'nc: '+str(num_classes)+' #'\n",
        "    replace_string = file_source.replace('nc:', new_string)\n",
        "\n",
        "with open('/content/yolov5/models/cacaov1_model.yaml', 'w') as f:\n",
        "    #save output\n",
        "    f.write(replace_string)\n",
        "\n",
        "%cat /content/yolov5/models/cacaov1_model.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the config file to the \"exported_files\" folder\n",
        "%cp /content/yolov5/models/cacaov1_model.yaml /content/exported_files\n",
        "%cp {dataset.location}/data.yaml /content/exported_files"
      ],
      "metadata": {
        "id": "yLHkaFuDU5Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUOiNLtMP5aG"
      },
      "source": [
        "# Step 5: Training the Cacao Maturity YOLOv5 Detector\n",
        "### Using the YOLOv5s (small) variant\n",
        "\n",
        "The arguments used for this training are:\n",
        "- **img:** input image size of 640\n",
        "- **batch:** Autobatch (-1)\n",
        "- **epochs:** 1000\n",
        "- **data:** the path to the yaml file\n",
        "- **cfg:** the model configuration\n",
        "- **weights:** the path to weights\n",
        "- **name:** yolov5_results\n",
        "- **nosave:** saves every 25th checkpoint\n",
        "- **cache:** cache images for faster training\n",
        "- **Comet Logging**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the model file\n",
        "!wget https://github.com/ultralytics/yolov5/releases/download/v7.0/$MODEL"
      ],
      "metadata": {
        "id": "siHWV72mAg2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "# train the \"MODEL\" on custom data for \"EPOCHS\" epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!env COMET_MAX_IMAGE_UPLOADS=1000 COMET_LOG_PER_CLASS_METRICS=true python train.py --img $IMG_SIZE --batch-size -1 --epochs $EPOCHS --data {dataset.location}/data.yaml --cfg ./models/cacaov1_model.yaml --weights $MODEL --name yolov5_results --bbox_interval 1 --save-period 25 --cache\n",
        "\n",
        "# copy the best model to the \"exported_files\" folder\n",
        "%cp /content/yolov5/runs/train/yolov5_results/weights/best.pt /content/exported_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVs_4zEeVbF"
      },
      "source": [
        "# Step 6: Evaluate Cacao Maturity Classifier Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
        "\n",
        "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOy5KI2ncnWd"
      },
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C60XAsyv6OPe"
      },
      "source": [
        "# we can also output some older school graphs if the tensor board isn't working for whatever reason...\n",
        "%cd /content/yolov5/\n",
        "from utils.plots import plot_results  # plot results.txt as results.png\n",
        "Image(filename='/content/yolov5/runs/train/yolov5_results/results.png', width=1000)  # view results.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLI1JmHU7B0l"
      },
      "source": [
        "### Visualize Our Training Data with Labels\n",
        "\n",
        "After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.\n",
        "\n",
        "Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF9MLHDb7tB6"
      },
      "source": [
        "# first, display our ground truth data\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/train/yolov5_results/*_batch0_labels.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName, width=900))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W40tI99_7BcH"
      },
      "source": [
        "# print out an augmented training example\n",
        "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5_results/train_batch0.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3qM6T0W53gh"
      },
      "source": [
        "# Step 7: Run Inference with the Classifier Model\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIEwt5YLeQ7P"
      },
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SyOWS80qR32"
      },
      "source": [
        "%ls runs/train/yolov5_results/weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nmZZnWOgJ2S"
      },
      "source": [
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/train/yolov5_results/weights/best.pt --img $IMG_SIZE --conf 0.4 --source {dataset.location}/test/images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odKEqYtTgbRc"
      },
      "source": [
        "#display inference on ALL test images\n",
        "#this looks much better with longer training above\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uPq9mVgiBql"
      },
      "source": [
        "# Step 8: Export the Classifier Model to TensorFlow Lite format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH4CTzDRh00g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429b3632-f1bb-4da5-acb5-9d22ac39ee63"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x_wg3VeiXMW"
      },
      "source": [
        "%cp /content/exported_files/* /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/exported_files.zip /content/exported_files"
      ],
      "metadata": {
        "id": "Oan3VC4llVO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/exported_files.zip')"
      ],
      "metadata": {
        "id": "-J5vslTXleLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export to FP16 TFLite (640 image size)\n",
        "!python export.py --weights runs/train/yolov5_results/weights/best.pt --include tflite --data /content/exported_files/data.yaml"
      ],
      "metadata": {
        "id": "52whCtDFqSeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export to INT8 TFLite (640 image size)\n",
        "!python export.py --weights runs/train/yolov5_results/weights/best.pt --include tflite --int8 --data /content/exported_files/data.yaml"
      ],
      "metadata": {
        "id": "cXe-6mFwWDUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export to FP16 TFLite (416 image size)\n",
        "!python export.py --weights runs/train/yolov5_results/weights/best.pt --img 416 --include tflite --data /content/exported_files/data.yaml"
      ],
      "metadata": {
        "id": "4ANhT7mnX8KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export to INT8 TFLite (416 image size)\n",
        "!python export.py --weights runs/train/yolov5_results/weights/best.pt --include tflite --int8 --img 416 --data /content/exported_files/data.yaml"
      ],
      "metadata": {
        "id": "c7_MmrfAYyBT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}